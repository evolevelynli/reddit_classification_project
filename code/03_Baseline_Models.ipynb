{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web APIs & Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Challenge Statement\n",
    "\n",
    "### Goal: \n",
    "#### 1. Using Reddit's API, collect posts from two subreddits: AskWomen, AskMen, Relationship_Advice. \n",
    "#### 2. NLP to train a classifier on which subreddit a given post came from. This is a binary classification problem.\n",
    "\n",
    "### Datasets: \n",
    "1. AskMen vs AskWomen (0, 1)\n",
    "2. AskMen vs Relationship Advice (0, 1)\n",
    "3. AskWomen vs Relationship Advice (0, 1)\n",
    "\n",
    "### Baseline Model Building \n",
    "Baseline models are built without using tokenizers, \n",
    "#### 1. CountVectorizer Model \n",
    "- with Logistic Regression \n",
    "- with Multinomial NB\n",
    "\n",
    "#### 2. TF-IDF Model\n",
    "- with Logistic Regression \n",
    "- with Multinomial NB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents \n",
    "\n",
    "This Notebook is broken down into different sections for analysis purpose. The following links are connected to differenct section within the Notebook for simple navigation. \n",
    "\n",
    "### Contents:\n",
    "- [CountVectorizer Model With Logistic Regression](#CountVectorizer-Model-With-Logistic-Regression)\n",
    "    1. AskMen vs AskWomen (0, 1)\n",
    "    2. AskMen vs Relationship Advice (0, 1)\n",
    "    3. AskWomen vs Relationship Advice (0, 1)\n",
    "    \n",
    "    \n",
    "- [CountVectorizer Model With Multinomal NB](#CountVectorizer-Model-With-Multinomal-NB)\n",
    "    1. AskMen vs AskWomen (0, 1)\n",
    "    2. AskMen vs Relationship Advice (0, 1)\n",
    "    3. AskWomen vs Relationship Advice (0, 1)\n",
    "    \n",
    "    \n",
    "- [TFIDF Model With Logistic Regression](#TFIDF-Model-With-Multinomal-NB)\n",
    "    1. AskMen vs AskWomen (0, 1)\n",
    "    2. AskMen vs Relationship Advice (0, 1)\n",
    "    3. AskWomen vs Relationship Advice (0, 1)\n",
    "    \n",
    "    \n",
    "- [TFIDF Model With Multinomal NB](#TFIDF-Model-With-Multinomal-NB)\n",
    "    1. AskMen vs AskWomen (0, 1)\n",
    "    2. AskMen vs Relationship Advice (0, 1)\n",
    "    3. AskWomen vs Relationship Advice (0, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import re\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "menwomen_df = pd.read_csv('../data/AskMenAskWomen.csv')\n",
    "menrelationship_df = pd.read_csv('../data/AskMen_Relationship.csv')\n",
    "womenrelationship_df = pd.read_csv('../data/AskWomen_Relationship.csv')\n",
    "multi_df = pd.read_csv('../data/AskMenWomen_Relationship.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>Title_Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The AskMen Book Club   The Picture of Dorian G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I am starting to realise my dad wont live fore...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>What do you see on women s dating profiles tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>What could women put in their dating profiles ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>What are some things on your mind that you can...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Subreddit                                      Title_Content\n",
       "0           0          0  The AskMen Book Club   The Picture of Dorian G...\n",
       "1           1          0  I am starting to realise my dad wont live fore...\n",
       "2           2          0  What do you see on women s dating profiles tha...\n",
       "3           3          0  What could women put in their dating profiles ...\n",
       "4           4          0  What are some things on your mind that you can..."
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "menwomen_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build custom tokenizers with lemmaliszer \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "def lemma(content):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(content.lower())\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens_lem = [lemmatizer.lemmatize(i) for i in tokens]\n",
    "    return(\" \".join(tokens_lem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build custom tokenizers with lemmaliszer \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "def stemmer(content):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(content.lower())\n",
    "    p_stemmer = PorterStemmer()\n",
    "    stem_tokens = [p_stemmer.stem(i) for i in tokens]\n",
    "    return(\" \".join(stem_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Model With Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building pipeline and gridsearch model \n",
    "#pipeline \n",
    "loggit_pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()), \n",
    "    ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "#parameters for grid search \n",
    "params_1 = {\n",
    "    'cvec__stop_words':[None, 'english'],\n",
    "    'cvec__max_features': [1000, 1500, 2000, 2500],\n",
    "    'cvec__min_df': [2, 5],\n",
    "    'cvec__max_df': [.95, 0.99],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)],\n",
    "#     'cvec__tokenizer':[None, lemma, stemmer]\n",
    "}\n",
    "\n",
    "#gridsearch \n",
    "gs1 = GridSearchCV(loggit_pipe, param_grid = params_1 , cv = 3)\n",
    "gs2 = GridSearchCV(loggit_pipe, param_grid = params_1 , cv = 3)\n",
    "gs3 = GridSearchCV(loggit_pipe, param_grid = params_1 , cv = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1 with menwomen_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = menwomen_df[\"Title_Content\"]\n",
    "y = menwomen_df['Subreddit']\n",
    "\n",
    "#Train Test Split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evelyn/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.95,\n",
       " 'cvec__max_features': 1500,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__ngram_range': (1, 2),\n",
       " 'cvec__stop_words': 'english'}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs1.fit(X_train, y_train)\n",
    "gs1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.9289805269186713\n",
      "test score 0.7013333333333334\n"
     ]
    }
   ],
   "source": [
    "print('train score', gs1.score(X_train, y_train))\n",
    "print('test score', gs1.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1 with menrelationship_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = menrelationship_df[\"Title_Content\"]\n",
    "y = menrelationship_df['Subreddit']\n",
    "\n",
    "#Train Test Split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evelyn/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.95,\n",
       " 'cvec__max_features': 2500,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': None}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs2.fit(X_train, y_train)\n",
    "gs2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.9990530303030303\n",
      "test score 0.9315673289183223\n"
     ]
    }
   ],
   "source": [
    "print('train score', gs2.score(X_train, y_train))\n",
    "print('test score', gs2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1 with  womenrelationship_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = womenrelationship_df[\"Title_Content\"]\n",
    "y = womenrelationship_df['Subreddit']\n",
    "\n",
    "#Train Test Split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evelyn/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.95,\n",
       " 'cvec__max_features': 2000,\n",
       " 'cvec__min_df': 5,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': None}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs2.fit(X_train, y_train)\n",
    "gs2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.998324958123953\n",
      "test score 0.98635477582846\n"
     ]
    }
   ],
   "source": [
    "print('train score', gs2.score(X_train, y_train))\n",
    "print('test score', gs2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer Model With Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building pipeline and gridsearch model \n",
    "#pipeline \n",
    "nb_pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()), \n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "\n",
    "#parameters for grid search \n",
    "params_2 = {\n",
    "    'cvec__stop_words':[None, 'english'],\n",
    "    'cvec__max_features': [1000, 1500, 2000, 2500],\n",
    "    'cvec__min_df': [2, 5],\n",
    "    'cvec__max_df': [.95, 0.99],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)]\n",
    "}\n",
    "\n",
    "#gridsearch \n",
    "gs4 = GridSearchCV(nb_pipe, param_grid = params_2 , cv = 3)\n",
    "gs5 = GridSearchCV(nb_pipe, param_grid = params_2 , cv = 3)\n",
    "gs6 = GridSearchCV(nb_pipe, param_grid = params_2 , cv = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2 with menwomen_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = menwomen_df[\"Title_Content\"]\n",
    "y = menwomen_df['Subreddit']\n",
    "\n",
    "#Train Test Split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.95,\n",
       " 'cvec__max_features': 1000,\n",
       " 'cvec__min_df': 5,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': 'english'}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs4.fit(X_train, y_train)\n",
    "gs4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.8029782359679267\n",
      "test score 0.6986666666666667\n"
     ]
    }
   ],
   "source": [
    "print('train score', gs4.score(X_train, y_train))\n",
    "print('test score', gs4.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2 with menrelationship_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = menrelationship_df[\"Title_Content\"]\n",
    "y = menrelationship_df['Subreddit']\n",
    "\n",
    "#Train Test Split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.95,\n",
       " 'cvec__max_features': 2000,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': None}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs5.fit(X_train, y_train)\n",
    "gs5.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.9517045454545454\n",
      "test score 0.9205298013245033\n"
     ]
    }
   ],
   "source": [
    "print('train score', gs5.score(X_train, y_train))\n",
    "print('test score', gs5.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2 with  womenrelationship_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = womenrelationship_df[\"Title_Content\"]\n",
    "y = womenrelationship_df['Subreddit']\n",
    "\n",
    "#Train Test Split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.95,\n",
       " 'cvec__max_features': 2000,\n",
       " 'cvec__min_df': 5,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': None}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs6.fit(X_train, y_train)\n",
    "gs6.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.981574539363484\n",
      "test score 0.9766081871345029\n"
     ]
    }
   ],
   "source": [
    "print('train score', gs6.score(X_train, y_train))\n",
    "print('test score', gs6.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF Model With Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building pipeline and gridsearch model \n",
    "#pipeline \n",
    "loggit_pipe2 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()), \n",
    "    ('logreg', LogisticRegression())\n",
    "])\n",
    "\n",
    "#parameters for grid search \n",
    "params_3 = {\n",
    "    'tfidf__stop_words':[None, 'english'],\n",
    "    'tfidf__max_features': [1000, 1500, 2000, 2500],\n",
    "    'tfidf__min_df': [2, 5],\n",
    "    'tfidf__max_df': [.95, 0.99],\n",
    "    'tfidf__ngram_range': [(1,1), (1,2)]\n",
    "}\n",
    "\n",
    "#gridsearch \n",
    "gs7 = GridSearchCV(loggit_pipe2, param_grid = params_3 , cv = 3)\n",
    "gs8 = GridSearchCV(loggit_pipe2, param_grid = params_3 , cv = 3)\n",
    "gs9 = GridSearchCV(loggit_pipe2, param_grid = params_3 , cv = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3 with menwomen_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = menwomen_df[\"Title_Content\"]\n",
    "y = menwomen_df['Subreddit']\n",
    "\n",
    "#Train Test Split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evelyn/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tfidf__max_df': 0.95,\n",
       " 'tfidf__max_features': 1000,\n",
       " 'tfidf__min_df': 2,\n",
       " 'tfidf__ngram_range': (1, 1),\n",
       " 'tfidf__stop_words': None}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs7.fit(X_train, y_train)\n",
    "gs7.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.8304696449026346\n",
      "test score 0.736\n"
     ]
    }
   ],
   "source": [
    "print('train score', gs7.score(X_train, y_train))\n",
    "print('test score', gs7.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3 with menrelationship_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = menrelationship_df[\"Title_Content\"]\n",
    "y = menrelationship_df['Subreddit']\n",
    "\n",
    "#Train Test Split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evelyn/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tfidf__max_df': 0.95,\n",
       " 'tfidf__max_features': 2000,\n",
       " 'tfidf__min_df': 5,\n",
       " 'tfidf__ngram_range': (1, 1),\n",
       " 'tfidf__stop_words': None}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs8.fit(X_train, y_train)\n",
    "gs8.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.9517045454545454\n",
      "test score 0.9227373068432672\n"
     ]
    }
   ],
   "source": [
    "print('train score', gs8.score(X_train, y_train))\n",
    "print('test score', gs8.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3 with  womenrelationship_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = womenrelationship_df[\"Title_Content\"]\n",
    "y = womenrelationship_df['Subreddit']\n",
    "\n",
    "#Train Test Split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evelyn/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tfidf__max_df': 0.95,\n",
       " 'tfidf__max_features': 1000,\n",
       " 'tfidf__min_df': 5,\n",
       " 'tfidf__ngram_range': (1, 1),\n",
       " 'tfidf__stop_words': None}"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs9.fit(X_train, y_train)\n",
    "gs9.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.9807370184254607\n",
      "test score 0.9805068226120858\n"
     ]
    }
   ],
   "source": [
    "print('train score', gs9.score(X_train, y_train))\n",
    "print('test score', gs9.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF Model With Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building pipeline and gridsearch model \n",
    "#pipeline \n",
    "nb_pipe2 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()), \n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "\n",
    "#parameters for grid search \n",
    "params_4 = {\n",
    "    'tfidf__stop_words':[None, 'english'],\n",
    "    'tfidf__max_features': [1000, 1500, 2000, 2500],\n",
    "    'tfidf__min_df': [2, 5],\n",
    "    'tfidf__max_df': [.95, 0.99],\n",
    "    'tfidf__ngram_range': [(1,1), (1,2)],\n",
    "#     'tfidf__tokenizer':[None, lemma, stemmer]\n",
    "}\n",
    "\n",
    "#gridsearch \n",
    "gs10 = GridSearchCV(nb_pipe2, param_grid = params_4 , cv = 3)\n",
    "gs11 = GridSearchCV(nb_pipe2, param_grid = params_4 , cv = 3)\n",
    "gs12 = GridSearchCV(nb_pipe2, param_grid = params_4 , cv = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 4 with menwomen_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = menwomen_df[\"Title_Content\"]\n",
    "y = menwomen_df['Subreddit']\n",
    "\n",
    "#Train Test Split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tfidf__max_df': 0.95,\n",
       " 'tfidf__max_features': 1000,\n",
       " 'tfidf__min_df': 2,\n",
       " 'tfidf__ngram_range': (1, 2),\n",
       " 'tfidf__stop_words': None}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs10.fit(X_train, y_train)\n",
    "gs10.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.7972508591065293\n",
      "test score 0.7146666666666667\n"
     ]
    }
   ],
   "source": [
    "print('train score', gs10.score(X_train, y_train))\n",
    "print('test score', gs10.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 4 with menrelationship_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = menrelationship_df[\"Title_Content\"]\n",
    "y = menrelationship_df['Subreddit']\n",
    "\n",
    "#Train Test Split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tfidf__max_df': 0.95,\n",
       " 'tfidf__max_features': 1500,\n",
       " 'tfidf__min_df': 5,\n",
       " 'tfidf__ngram_range': (1, 2),\n",
       " 'tfidf__stop_words': None}"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs11.fit(X_train, y_train)\n",
    "gs11.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.928030303030303\n",
      "test score 0.9183222958057395\n"
     ]
    }
   ],
   "source": [
    "print('train score', gs11.score(X_train, y_train))\n",
    "print('test score', gs11.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 4 with  womenrelationship_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = womenrelationship_df[\"Title_Content\"]\n",
    "y = womenrelationship_df['Subreddit']\n",
    "\n",
    "#Train Test Split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tfidf__max_df': 0.95,\n",
       " 'tfidf__max_features': 1500,\n",
       " 'tfidf__min_df': 2,\n",
       " 'tfidf__ngram_range': (1, 2),\n",
       " 'tfidf__stop_words': None}"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs12.fit(X_train, y_train)\n",
    "gs12.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.9824120603015075\n",
      "test score 0.9766081871345029\n"
     ]
    }
   ],
   "source": [
    "print('train score', gs12.score(X_train, y_train))\n",
    "print('test score', gs12.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
