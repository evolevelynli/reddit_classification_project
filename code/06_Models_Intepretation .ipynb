{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web APIs & Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Challenge Statement\n",
    "\n",
    "### Goal: \n",
    "#### 1. Using Reddit's API, collect posts from three subreddits: AskWomen, AskMen, Relationship_Advice. \n",
    "#### 2. NLP to train a classifier on which subreddit a given post came from. This is a binary classification problem.\n",
    "\n",
    "---\n",
    "\n",
    "### Datasets: \n",
    "\n",
    "1. AskMen:0, AskWomen:1, WordCounts \n",
    "3. RelationshipAdvice:0, AskWomen:1, WordCounts\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Notebook Walkthrough \n",
    "\n",
    "1. Models Walkthrough\n",
    "2. Models Analysis \n",
    "3. Key Takeaways  \n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents \n",
    "\n",
    "This Notebook is broken down into different sections for analysis purpose. The following links are connected to differenct section within the Notebook for simple navigation. \n",
    "\n",
    "---\n",
    "\n",
    "### Contents:\n",
    "- [Models Walkthrough](#Models-Walkthrough)\n",
    "- [Models Analysis](#Models-Analysis)\n",
    "    - [Hypothesis 1, large train test gap => large overlap of common words](#Hypothesis-1,-large-train-test-gap-=>-large-overlap-of-common-words)\n",
    "    - [Hypothesis 2, small train test gap => small overlap of common words](#Hypothesis-2,-small-train-test-gap-=>-small-overlap-of-common-words)\n",
    "- [Key Takeaways](#Key-Takeaways)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Walkthrough\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to use natural language processing techniques to train a classifier to identify which subreddits. The data of this project comes from Reddit, and three subreddits are chosen to build the model, they are AskWomen, AskMen, and Relationship Advice.  Two data frames are constructed using these three subreddits. The first data frame contains topics and contents from both subreddits AskMen and AskWomen. In the first data frame, the target variable is AskMen subreddit, and the model is trying to classify AskMen subreddit from AskWomen using NPL techniques.  For comparison purposes in understanding how the model works and what keywords the model used for classification purpose, I flip the target and change AskWomen subreddit posts as the target for classification. The second data frame contains topics and contents from subreddits Relationship Advice and AskWomen where Relationship Advice is the target. There is a slight tweak of the natural language processing model due to the difference in content, but the concept is similar for both models.  \n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Models Analysis\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 The Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Models : \n",
    "So far, there are many different models we can use to achieve the goal of classification. Without using all of them, there is no way we can understand which model works better. Therefore, I used seven models that I consider as appropriate for the goal of classification. Here is a list of all seven of them: \n",
    "\n",
    "1. CountVectorizer Model With Logistic Regression\n",
    "2. CountVectorizer Model With Multinomial NB\n",
    "3. TFIDF Model With Logistic Regression\n",
    "4. TFIDF Model With Multinomial NB\n",
    "5. Random Forest Model Feature Extraction\n",
    "6. Extra Tree Model Feature Extraction\n",
    "7. AdaBoost classifier Model Feature Extraction\n",
    "\n",
    "After fitting all the models, I noticed that some models perform better than others. For example, the multinomial naive Bayes model works well in general, and the AdaBoost classifier model is overfitting in both datasets. With the above observation, I decided to combine all seven models and build one ensemble model. The following scores are the train and test score for each ensemble model I constructed for two datasets. \n",
    "\n",
    "\n",
    "\n",
    "For AskMen and AskWomen Dataset with Target = AskWomen\n",
    "\n",
    "```\n",
    "train score 0.92\n",
    "test score 0.73\n",
    "\n",
    "```\n",
    "\n",
    "For AskMen and AskWomen Dataset with Target = AskMen\n",
    "\n",
    "```\n",
    "train score 0.87\n",
    "test score 0.74\n",
    "\n",
    "```\n",
    "For AskWomen and Relationship Advice Dataset with Target = AskWomen \n",
    "\n",
    "```\n",
    "train score 0.999\n",
    "test score 0.976\n",
    "```\n",
    "For AskWomen and Relationship Advice Dataset with Target = Relationship Advice\n",
    "```\n",
    "train score 0.993\n",
    "test score 0.982\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So what is happening? \n",
    "\n",
    "With the same baseline content from AskWomen subreddit, the classifier is trying to distinguish blog post from AskMen and Relationship Advice. However, as one can see, the training score and testing score are entirely different from one dataset to the other. I have tried many models and grid search over a different number of parameters (keywords) to improve the score of train and test. However, tunning the model doesn't seem to do much to the score. Therefore, I am going to look at the number of most common words in each subreddit and find the percentage of overlap words. \n",
    "\n",
    "### **Hypothesis** \n",
    "- Large train test gap\t\t=> More overlap in top Features \n",
    "- Small train test gap\t\t=> Less overlap in top features\n",
    "\n",
    "**My hypothesis 1 :**\n",
    "\n",
    "For the model that has a large gap between training and testing score,  the percentage of overlap for top features will be higher. \n",
    "\n",
    "The process to confirm the hypothesis: \n",
    "1. Look into the top 100 most common words in AskMen and AskWomen. \n",
    "2. Look into the top 100 features after plotting the model for AskMen and AskWomen.\n",
    "\n",
    "**My hypothesis 2 :**\n",
    "\n",
    "For the model that has a small gap between training and testing score,  the percentage of overlap for top features will be lower. \n",
    "\n",
    "The process to confirm the hypothesis: \n",
    "1. Look into the top 100 most common words in AskWomen and Relationship Advice. \n",
    "2. Look into the top 100 features after plotting the model for AskWomen and Relationship Advice.\n",
    "\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis 1, large train test gap => large overlap of common words\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import datasets \n",
    "women1_count = pd.read_csv('../data/AskMen0AskWomen1wordcount.csv')\n",
    "women1_coeff = pd.read_csv('../data/AskMen0AskWomen1wordcoeff.csv')\n",
    "men1_count = pd.read_csv('../data/AskMen1AskWomen0wordcount.csv')\n",
    "men1_coeff = pd.read_csv('../data/AskMen1AskWomen0wordcoeff.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>AskMen</th>\n",
       "      <th>AskWomen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>you</td>\n",
       "      <td>40.694791</td>\n",
       "      <td>28.624296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>what</td>\n",
       "      <td>31.534464</td>\n",
       "      <td>20.296435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>to</td>\n",
       "      <td>29.553963</td>\n",
       "      <td>18.756743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>do</td>\n",
       "      <td>23.625515</td>\n",
       "      <td>16.424676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>your</td>\n",
       "      <td>26.823695</td>\n",
       "      <td>16.341694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0     AskMen   AskWomen\n",
       "1422        you  40.694791  28.624296\n",
       "1314       what  31.534464  20.296435\n",
       "1178         to  29.553963  18.756743\n",
       "264          do  23.625515  16.424676\n",
       "1480       your  26.823695  16.341694"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sort by number of occurance target = AskWomen\n",
    "women1_count.sort_values(by = 'AskWomen', ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you', 'what', 'to', 'do', 'your']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top 100 word list for AskWomen\n",
    "women1_top100word = list(women1_count.sort_values(by = 'AskWomen', ascending = False).head(300)['Unnamed: 0'])\n",
    "women1_top100word[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>AskMen</th>\n",
       "      <th>AskWomen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>you</td>\n",
       "      <td>40.694791</td>\n",
       "      <td>28.624296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>what</td>\n",
       "      <td>31.534464</td>\n",
       "      <td>20.296435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>to</td>\n",
       "      <td>29.553963</td>\n",
       "      <td>18.756743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>the</td>\n",
       "      <td>29.164440</td>\n",
       "      <td>15.120878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>your</td>\n",
       "      <td>26.823695</td>\n",
       "      <td>16.341694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0     AskMen   AskWomen\n",
       "1422        you  40.694791  28.624296\n",
       "1314       what  31.534464  20.296435\n",
       "1178         to  29.553963  18.756743\n",
       "1098        the  29.164440  15.120878\n",
       "1480       your  26.823695  16.341694"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "men1_count.sort_values(by = 'AskMen', ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you', 'what', 'to', 'the', 'your']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top 100 word list for AskMen\n",
    "men1_top100word = list(men1_count.sort_values(by = 'AskMen', ascending = False).head(300)['Unnamed: 0'])\n",
    "men1_top100word[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n"
     ]
    }
   ],
   "source": [
    "print(len(set(women1_top100word) & set(men1_top100word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(women1_count.sort_values(by = 'AskWomen', ascending = False)['Unnamed: 0'].head(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AskMen AskWomen Most Common Words Overlap Percentage\n",
      "within top 100 word, the overlap is 0.81\n",
      "within top 300 word, the overlap is 0.7266666666666667\n",
      "within top 500 word, the overlap is 0.676\n"
     ]
    }
   ],
   "source": [
    "#Top Word Counts for MenWomen DataSets Without fitting Models \n",
    "print(\"AskMen AskWomen Most Common Words Overlap Percentage\")\n",
    "for i in [100, 300, 500]: \n",
    "    women1_topword = list(women1_count.sort_values(by = 'AskWomen', ascending = False).head(i)['Unnamed: 0'])\n",
    "    men1_topword = list(men1_count.sort_values(by = 'AskMen', ascending = False).head(i)['Unnamed: 0'])\n",
    "    print(f'within top {i} word, the overlap is {len(set(women1_topword).intersection(set(men1_topword)))/i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>nb_coef_switched</th>\n",
       "      <th>logit_coef_switched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>men</td>\n",
       "      <td>-5.973712</td>\n",
       "      <td>2.316345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>guys</td>\n",
       "      <td>-6.145557</td>\n",
       "      <td>2.090470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>my</td>\n",
       "      <td>-5.529801</td>\n",
       "      <td>1.924988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>to</td>\n",
       "      <td>-4.810618</td>\n",
       "      <td>1.653101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>and</td>\n",
       "      <td>-4.994186</td>\n",
       "      <td>1.596805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>she</td>\n",
       "      <td>-6.118351</td>\n",
       "      <td>1.190787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>her</td>\n",
       "      <td>-6.138620</td>\n",
       "      <td>1.107499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>out</td>\n",
       "      <td>-6.014033</td>\n",
       "      <td>1.055357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>men of</td>\n",
       "      <td>-6.776649</td>\n",
       "      <td>1.032370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>that</td>\n",
       "      <td>-5.401980</td>\n",
       "      <td>0.946948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  nb_coef_switched  logit_coef_switched\n",
       "734         men         -5.973712             2.316345\n",
       "452        guys         -6.145557             2.090470\n",
       "764          my         -5.529801             1.924988\n",
       "1180         to         -4.810618             1.653101\n",
       "41          and         -4.994186             1.596805\n",
       "982         she         -6.118351             1.190787\n",
       "498         her         -6.138620             1.107499\n",
       "859         out         -6.014033             1.055357\n",
       "735      men of         -6.776649             1.032370\n",
       "1084       that         -5.401980             0.946948"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top feature by sorting logistic regression coefficient \n",
    "men1_coeff.sort_values(by = \"logit_coef_switched\", ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>nb_coef</th>\n",
       "      <th>logit_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>guys who</td>\n",
       "      <td>-8.179097</td>\n",
       "      <td>-0.790965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>for it</td>\n",
       "      <td>-8.179097</td>\n",
       "      <td>-0.088054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ask her</td>\n",
       "      <td>-8.179097</td>\n",
       "      <td>-0.059461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>class</td>\n",
       "      <td>-8.179097</td>\n",
       "      <td>-0.131403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>he is</td>\n",
       "      <td>-8.179097</td>\n",
       "      <td>-0.102100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>whenever</td>\n",
       "      <td>-8.179097</td>\n",
       "      <td>-0.266105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>gf</td>\n",
       "      <td>-8.179097</td>\n",
       "      <td>-0.519240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>head</td>\n",
       "      <td>-8.179097</td>\n",
       "      <td>-0.496253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>men of</td>\n",
       "      <td>-8.179097</td>\n",
       "      <td>-0.885945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>father</td>\n",
       "      <td>-8.179097</td>\n",
       "      <td>-0.131840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   nb_coef  logit_coef\n",
       "449    guys who -8.179097   -0.790965\n",
       "382      for it -8.179097   -0.088054\n",
       "98      ask her -8.179097   -0.059461\n",
       "196       class -8.179097   -0.131403\n",
       "486       he is -8.179097   -0.102100\n",
       "1348   whenever -8.179097   -0.266105\n",
       "424          gf -8.179097   -0.519240\n",
       "488        head -8.179097   -0.496253\n",
       "736      men of -8.179097   -0.885945\n",
       "353      father -8.179097   -0.131840"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top feature by sorting logistic regression coefficient \n",
    "women1_coeff.sort_values(by = \"nb_coef\", ascending = True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AskMen AskWomen Logistic Regression Top Features Overlap\n",
      "within top 100 features, the overlap of top features is 0.0\n",
      "within top 200 features, the overlap of top features is 0.0\n",
      "within top 300 features, the overlap of top features is 0.02\n",
      "within top 400 features, the overlap of top features is 0.0375\n",
      "within top 500 features, the overlap of top features is 0.062\n"
     ]
    }
   ],
   "source": [
    "#Top Word Features for MenWomen DataSets After fitting Logistic Regression Models\n",
    "model1_logit_overlap = []\n",
    "print('AskMen AskWomen Logistic Regression Top Features Overlap')\n",
    "for i in [100, 200, 300, 400, 500]: \n",
    "    women1_topfeature = list(women1_coeff.sort_values(by = \"logit_coef\", \n",
    "                                                      ascending = False).head(i)['Unnamed: 0'])\n",
    "    men1_topfeature = list(men1_coeff.sort_values(by = \"logit_coef_switched\", \n",
    "                                                  ascending = False).head(i)['Unnamed: 0'])\n",
    "    percentage = len(set(women1_topfeature).intersection(set(men1_topfeature)))/i\n",
    "    model1_logit_overlap.append(len(set(women1_topfeature).intersection(set(men1_topfeature))))\n",
    "    print(f'within top {i} features, the overlap of top features is {percentage}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AskMen AskWomen Naive Bayes Top Features Overlap\n",
      "within top 100 features, the overlap of top features is 0.71\n",
      "within top 200 features, the overlap of top features is 0.685\n",
      "within top 300 features, the overlap of top features is 0.6466666666666666\n",
      "within top 400 features, the overlap of top features is 0.64\n",
      "within top 500 features, the overlap of top features is 0.624\n"
     ]
    }
   ],
   "source": [
    "#Top Word Features for MenWomen DataSets After fitting NB Models\n",
    "model1_nb_overlap = []\n",
    "print('AskMen AskWomen Naive Bayes Top Features Overlap')\n",
    "for i in [100, 200, 300, 400, 500]: \n",
    "    women1_topfeature = list(women1_coeff.sort_values(by = \"nb_coef\", ascending = False).head(i)['Unnamed: 0'])\n",
    "    men1_topfeature = list(men1_coeff.sort_values(by = \"nb_coef_switched\", ascending = False).head(i)['Unnamed: 0'])\n",
    "    percentage = len(set(women1_topfeature).intersection(set(men1_topfeature)))/i\n",
    "    model1_nb_overlap.append(percentage)\n",
    "    print(f'within top {i} features, the overlap of top features is {percentage}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Conclusion for Hypothesis 1: \n",
    "\n",
    "---\n",
    "\n",
    "Although within the top, and up to 1000 most common words in the AskMen and AskWomen subreddits, the number of overlap common words is significant: \n",
    "\n",
    "| Top Common Words |  Common Words Overlap  |\n",
    "|:----------------:|:----------------------:|\n",
    "|        100       |          0.81          |\n",
    "|        300       |          0.727         |\n",
    "|        500       |          0.676         |\n",
    "\n",
    "However, after we fit the model and pull out the most significant features up to 500 features from both Logistic Regression model and Naive Bayes Model, we see less overlaps in top features untill we reach about top 400 features for logistic regression. \n",
    "\n",
    "| # Of Top Features  | Log Reg Overlap | NB Overlap |\n",
    "|:-------------:|:---------------:|:----------:|\n",
    "|      100      |       0.0       |    0.71    |\n",
    "|      200      |       0.0       |    0.685    |\n",
    "|      300      |       0.02      |    0.646   |\n",
    "|      400      |      0.0375     |    0.64    |\n",
    "|      500      |      0.062      |    0.624   |\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis 2, small train test gap => small overlap of common words\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import datasets \n",
    "women2_count = pd.read_csv('../data/Relatioinship0AskWomen1wordcount.csv')\n",
    "women2_coeff = pd.read_csv('../data/Relatioinship0AskWomen1wordcoeff.csv')\n",
    "relationship1_count = pd.read_csv('../data/AskWomen0RelationshipAdvice1wordcount.csv')\n",
    "relationship1_coeff = pd.read_csv('../data/AskWomen0RelationshipAdvice1wordcoeff.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1500, 3), (1500, 3), (1500, 3), (1500, 3))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "women2_count.shape, women2_coeff.shape, relationship1_count.shape, relationship1_coeff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>AskWomen</th>\n",
       "      <th>RelationshipAdvice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>and</td>\n",
       "      <td>53.329890</td>\n",
       "      <td>87.391961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>to</td>\n",
       "      <td>52.960465</td>\n",
       "      <td>85.770449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>the</td>\n",
       "      <td>39.056518</td>\n",
       "      <td>57.914291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>you</td>\n",
       "      <td>36.010009</td>\n",
       "      <td>56.960820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>he</td>\n",
       "      <td>33.075412</td>\n",
       "      <td>53.777860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   AskWomen  RelationshipAdvice\n",
       "49          and  53.329890           87.391961\n",
       "1264         to  52.960465           85.770449\n",
       "1181        the  39.056518           57.914291\n",
       "1490        you  36.010009           56.960820\n",
       "513          he  33.075412           53.777860"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sort by number of occurance target = AskWomen\n",
    "women2_count.sort_values(by = 'AskWomen', ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>RelationshipAdvice</th>\n",
       "      <th>AskWomen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>and</td>\n",
       "      <td>85.465545</td>\n",
       "      <td>55.908178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>to</td>\n",
       "      <td>82.468045</td>\n",
       "      <td>56.510292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>the</td>\n",
       "      <td>58.674563</td>\n",
       "      <td>37.868873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>you</td>\n",
       "      <td>53.887508</td>\n",
       "      <td>37.520461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>he</td>\n",
       "      <td>53.275884</td>\n",
       "      <td>33.657295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  RelationshipAdvice   AskWomen\n",
       "48          and           85.465545  55.908178\n",
       "1259         to           82.468045  56.510292\n",
       "1178        the           58.674563  37.868873\n",
       "1491        you           53.887508  37.520461\n",
       "517          he           53.275884  33.657295"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relationship1_count.sort_values(by = 'RelationshipAdvice', ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Women Relationship Advice Most Common Words Overlap Percentage\n",
      "within top 100 word, the overlap is 0.92\n",
      "within top 200 word, the overlap is 0.905\n",
      "within top 500 word, the overlap is 0.878\n"
     ]
    }
   ],
   "source": [
    "#Top Word Counts for Women and Relationship Advice DataSets Without fitting Models \n",
    "print(\"Women Relationship Advice Most Common Words Overlap Percentage\")\n",
    "for i in [100, 200, 500]: \n",
    "    women2_topword = list(women2_count.sort_values(by = 'AskWomen', ascending = False).head(i)['Unnamed: 0'])\n",
    "    relationship_topword = list(relationship1_count.sort_values(by = 'RelationshipAdvice', ascending = False).head(i)['Unnamed: 0'])\n",
    "    print(f'within top {i} word, the overlap is {len(set(women2_topword).intersection(set(relationship_topword)))/i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>nb_coef</th>\n",
       "      <th>logit_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>you</td>\n",
       "      <td>-3.751280</td>\n",
       "      <td>3.546970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1416</th>\n",
       "      <td>what</td>\n",
       "      <td>-4.148849</td>\n",
       "      <td>2.811666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>your</td>\n",
       "      <td>-4.070718</td>\n",
       "      <td>2.248796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>do you</td>\n",
       "      <td>-4.518230</td>\n",
       "      <td>1.729328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>women</td>\n",
       "      <td>-5.194354</td>\n",
       "      <td>1.404916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>what is</td>\n",
       "      <td>-5.112346</td>\n",
       "      <td>1.289274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>what are</td>\n",
       "      <td>-5.113371</td>\n",
       "      <td>1.055633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>did you</td>\n",
       "      <td>-5.312946</td>\n",
       "      <td>0.990316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>ladies</td>\n",
       "      <td>-5.574215</td>\n",
       "      <td>0.968368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>how did</td>\n",
       "      <td>-5.663323</td>\n",
       "      <td>0.818149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423</th>\n",
       "      <td>what the</td>\n",
       "      <td>-5.727291</td>\n",
       "      <td>0.702583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>woman</td>\n",
       "      <td>-5.955257</td>\n",
       "      <td>0.687746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>when you</td>\n",
       "      <td>-5.656486</td>\n",
       "      <td>0.663387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>hair</td>\n",
       "      <td>-6.254134</td>\n",
       "      <td>0.627703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>have you</td>\n",
       "      <td>-5.713942</td>\n",
       "      <td>0.627676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>who</td>\n",
       "      <td>-5.591695</td>\n",
       "      <td>0.608400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>did</td>\n",
       "      <td>-5.339367</td>\n",
       "      <td>0.607888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>would you</td>\n",
       "      <td>-5.585623</td>\n",
       "      <td>0.585096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>you feel</td>\n",
       "      <td>-5.764115</td>\n",
       "      <td>0.571796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>that you</td>\n",
       "      <td>-6.015073</td>\n",
       "      <td>0.564684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   nb_coef  logit_coef\n",
       "1490        you -3.751280    3.546970\n",
       "1416       what -4.148849    2.811666\n",
       "1499       your -4.070718    2.248796\n",
       "317      do you -4.518230    1.729328\n",
       "1465      women -5.194354    1.404916\n",
       "1420    what is -5.112346    1.289274\n",
       "1417   what are -5.113371    1.055633\n",
       "302     did you -5.312946    0.990316\n",
       "692      ladies -5.574215    0.968368\n",
       "594     how did -5.663323    0.818149\n",
       "1423   what the -5.727291    0.702583\n",
       "1464      woman -5.955257    0.687746\n",
       "1433   when you -5.656486    0.663387\n",
       "486        hair -6.254134    0.627703\n",
       "510    have you -5.713942    0.627676\n",
       "1441        who -5.591695    0.608400\n",
       "299         did -5.339367    0.607888\n",
       "1479  would you -5.585623    0.585096\n",
       "1492   you feel -5.764115    0.571796\n",
       "1180   that you -6.015073    0.564684"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sort by significance of coefficientss for women(target) and relationship advice dataframe\n",
    "women2_coeff.sort_values(by = 'logit_coef', ascending= False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>nb_coef_switched</th>\n",
       "      <th>logit_coef_switched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>and</td>\n",
       "      <td>-4.253006</td>\n",
       "      <td>3.018729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>to</td>\n",
       "      <td>-4.334256</td>\n",
       "      <td>2.313939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>he</td>\n",
       "      <td>-4.614620</td>\n",
       "      <td>2.804925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>she</td>\n",
       "      <td>-4.690114</td>\n",
       "      <td>2.611810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>the</td>\n",
       "      <td>-4.786272</td>\n",
       "      <td>0.803423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>her</td>\n",
       "      <td>-4.857493</td>\n",
       "      <td>2.157683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>me</td>\n",
       "      <td>-4.888376</td>\n",
       "      <td>2.441805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>my</td>\n",
       "      <td>-4.910471</td>\n",
       "      <td>2.511056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>it</td>\n",
       "      <td>-5.009908</td>\n",
       "      <td>1.373701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>that</td>\n",
       "      <td>-5.026045</td>\n",
       "      <td>0.826481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  nb_coef_switched  logit_coef_switched\n",
       "48          and         -4.253006             3.018729\n",
       "1259         to         -4.334256             2.313939\n",
       "517          he         -4.614620             2.804925\n",
       "1041        she         -4.690114             2.611810\n",
       "1178        the         -4.786272             0.803423\n",
       "550         her         -4.857493             2.157683\n",
       "765          me         -4.888376             2.441805\n",
       "825          my         -4.910471             2.511056\n",
       "651          it         -5.009908             1.373701\n",
       "1156       that         -5.026045             0.826481"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sort by significance of coefficientss for women and relationship(target) dataframe \n",
    "relationship1_coeff.sort_values(by = 'nb_coef_switched', ascending= False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>nb_coef_switched</th>\n",
       "      <th>logit_coef_switched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>and</td>\n",
       "      <td>-4.253006</td>\n",
       "      <td>3.018729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>he</td>\n",
       "      <td>-4.614620</td>\n",
       "      <td>2.804925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>she</td>\n",
       "      <td>-4.690114</td>\n",
       "      <td>2.611810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>my</td>\n",
       "      <td>-4.910471</td>\n",
       "      <td>2.511056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>me</td>\n",
       "      <td>-4.888376</td>\n",
       "      <td>2.441805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>to</td>\n",
       "      <td>-4.334256</td>\n",
       "      <td>2.313939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>her</td>\n",
       "      <td>-4.857493</td>\n",
       "      <td>2.157683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>we</td>\n",
       "      <td>-5.104240</td>\n",
       "      <td>1.914438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>him</td>\n",
       "      <td>-5.267039</td>\n",
       "      <td>1.575202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>this</td>\n",
       "      <td>-5.392376</td>\n",
       "      <td>1.566193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>it</td>\n",
       "      <td>-5.009908</td>\n",
       "      <td>1.373701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>don</td>\n",
       "      <td>-5.838110</td>\n",
       "      <td>1.224792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>but</td>\n",
       "      <td>-5.294294</td>\n",
       "      <td>1.210994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>am</td>\n",
       "      <td>-6.121595</td>\n",
       "      <td>0.977603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>with</td>\n",
       "      <td>-5.253350</td>\n",
       "      <td>0.962981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>relationship</td>\n",
       "      <td>-6.046256</td>\n",
       "      <td>0.943873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>know</td>\n",
       "      <td>-5.952520</td>\n",
       "      <td>0.943639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>just</td>\n",
       "      <td>-5.664378</td>\n",
       "      <td>0.898428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>help</td>\n",
       "      <td>-6.689355</td>\n",
       "      <td>0.884828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>that</td>\n",
       "      <td>-5.026045</td>\n",
       "      <td>0.826481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  nb_coef_switched  logit_coef_switched\n",
       "48             and         -4.253006             3.018729\n",
       "517             he         -4.614620             2.804925\n",
       "1041           she         -4.690114             2.611810\n",
       "825             my         -4.910471             2.511056\n",
       "765             me         -4.888376             2.441805\n",
       "1259            to         -4.334256             2.313939\n",
       "550            her         -4.857493             2.157683\n",
       "1384            we         -5.104240             1.914438\n",
       "568            him         -5.267039             1.575202\n",
       "1231          this         -5.392376             1.566193\n",
       "651             it         -5.009908             1.373701\n",
       "323            don         -5.838110             1.224792\n",
       "204            but         -5.294294             1.210994\n",
       "43              am         -6.121595             0.977603\n",
       "1448          with         -5.253350             0.962981\n",
       "992   relationship         -6.046256             0.943873\n",
       "684           know         -5.952520             0.943639\n",
       "672           just         -5.664378             0.898428\n",
       "549           help         -6.689355             0.884828\n",
       "1156          that         -5.026045             0.826481"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relationship1_coeff.sort_values(by = 'logit_coef_switched', ascending= False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Women Relationship Advice Logistic Regression Top Features Overlap\n",
      "within top 100 features, the overlap of top features is 0.0\n",
      "within top 200 features, the overlap of top features is 0.0\n",
      "within top 300 features, the overlap of top features is 0.013333333333333334\n",
      "within top 400 features, the overlap of top features is 0.035\n",
      "within top 500 features, the overlap of top features is 0.046\n"
     ]
    }
   ],
   "source": [
    "#Top Word Features for MenWomen DataSets After fitting Logistic Regression Models\n",
    "model2_logit_overlap = []\n",
    "print('Women Relationship Advice Logistic Regression Top Features Overlap')\n",
    "for i in [100, 200, 300, 400, 500]: \n",
    "    women2_topfeature = list(women2_coeff.sort_values(by = 'logit_coef', \n",
    "                                                      ascending= False).head(i)['Unnamed: 0'])\n",
    "    relationship_topfeature = list(relationship1_coeff.sort_values(by = 'logit_coef_switched',\n",
    "                                                           ascending= False).head(i)['Unnamed: 0'])\n",
    "    percentage = len(set(women2_topfeature).intersection(set(relationship_topfeature)))/i\n",
    "    model2_logit_overlap.append(len(set(women2_topfeature).intersection(set(relationship_topfeature))))\n",
    "    print(f'within top {i} features, the overlap of top features is {percentage}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Women Relationship Advice NB Top Features Overlap\n",
      "within top 100 features, the overlap of top features is 0.43\n",
      "within top 200 features, the overlap of top features is 0.5\n",
      "within top 300 features, the overlap of top features is 0.5033333333333333\n",
      "within top 400 features, the overlap of top features is 0.53\n",
      "within top 500 features, the overlap of top features is 0.566\n"
     ]
    }
   ],
   "source": [
    "model2_nb_overlap = []\n",
    "print('Women Relationship Advice NB Top Features Overlap')\n",
    "for i in [100, 200, 300, 400, 500]: \n",
    "    women2_topfeature = list(women2_coeff.sort_values(by = 'nb_coef', \n",
    "                                                      ascending= False ).head(i)['Unnamed: 0'])\n",
    "    relationship_topfeature = list(relationship1_coeff.sort_values(by = 'nb_coef_switched',\n",
    "                                                           ascending= False).head(i)['Unnamed: 0'])\n",
    "    percentage = len(set(women2_topfeature).intersection(set(relationship_topfeature)))/i\n",
    "    model2_nb_overlap.append(len(set(women2_topfeature).intersection(set(relationship_topfeature))))\n",
    "    print(f'within top {i} features, the overlap of top features is {percentage}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(women2_coeff.sort_values(by = 'logit_coef', ascending= False ).head(100)['Unnamed: 0']).intersection(set(relationship1_coeff.sort_values(by = 'logit_coef_switched',ascending= False).head(100)['Unnamed: 0']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Conclusion for Hypothesis 2: \n",
    "\n",
    "---\n",
    "\n",
    "Our hypothesis says that if the model is doing good, then the number overlap words for the most common words will be small. We have proved this hypothesis is true : \n",
    "\n",
    "| Top Common Words |  Common Words Overlap  |\n",
    "|:----------------:|:----------------------:|\n",
    "|        100       |          0.92          |\n",
    "|        300       |          0.905         |\n",
    "|        1000      |          0.878          |\n",
    "\n",
    "After we fit the model and pull out the most significant features up to 500 features from both Logistic Regression model and Naive Bayes Model, we see less overlaps in top features comparing to the model that had had large gap between train test score: \n",
    "\n",
    "| # Of Top Features  | Log Reg Overlap | NB Overlap |\n",
    "|:-------------:|:---------------:|:----------:|\n",
    "|      100      |       0.00       |    0.43    |\n",
    "|      200      |       0.00       |    0.5    |\n",
    "|      300      |       0.013      |    0.503   |\n",
    "|      400      |       0.035       |    0.53    |\n",
    "|      500      |       0.046      |    0.566  |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I focus on understanding the question why with the same model apply to two different datasets, model perform well on one but not on the other. To understand the model, we made a hypothesis regarding the content of the subreddits. if two subreddits have a lot of in common, the model will perform poorly in distingushing one from the other. On the other hand, if two subreddit have different content and keywords, the model is better at picking up the different keywords regrading the different topics, and be better at distingushing the difference. \n",
    "\n",
    "Although this concept seems to be a common sense to us human beings, to fully understand how to model works, I decided to jump into this rabbit hole and figure out if the model actually works the same way as we assume it to work. \n",
    "\n",
    "After a long process of teasing out the keywords and coeffients, I have come to the conclusion that the model works better when there are less overlap keywords between subreddits. I also notice couple other things that are quite interesting: \n",
    "1. The most common words in a subreddit are not necessary the ones the model pick up as the key identifiers. This phenomenon can be due to the fact that we use TFIDF to tease out the most impactful words instead of the ones that are most common. \n",
    "2. Although the train test score gap of the model is large when it comes to similar content, the model is still quite good at picking up the difference between two subreddits. We can see this from looking at the overlap of the top features. Up to the top 300 features, the overlaping features between the similar subreddits is only 1% for Logistic regression model.\n",
    "3. When a model become more complex, the intepretation of the model start to become more complex and less easy to understand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
