{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web APIs & Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Challenge Statement\n",
    "\n",
    "### Goal: \n",
    "#### 1. Using Reddit's API, collect posts from two subreddits: AskWomen, AskMen, Relationship_Advice. \n",
    "#### 2. NLP to train a classifier on which subreddit a given post came from. This is a binary classification problem.\n",
    "\n",
    "### Datasets: \n",
    "1. AskMen vs AskWomen (0, 1)\n",
    "2. AskMen vs Relationship Advice (0, 1)\n",
    "3. AskWomen vs Relationship Advice (0, 1)\n",
    "\n",
    "### Model Improvement\n",
    "Use all baseline models to build ensemble model. \n",
    "\n",
    "#### 1. Ensemble Model \n",
    "- with CountVectorizer \n",
    "- with TFIDF Model\n",
    "- with Logistic Regression \n",
    "- with Multinomial NB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents \n",
    "\n",
    "This Notebook is broken down into different sections for analysis purpose. The following links are connected to differenct section within the Notebook for simple navigation. \n",
    "\n",
    "### Contents:\n",
    "- [Ensamble Model 2 menrelationship_df With Best Parameters](#Ensamble-Model-1-menwomen_df-With-Best-Parameters)\n",
    "    - [Ensamble Model 2: ](#Ensamble-Model-1)\n",
    "    - [Extracting Coefficients](#Extracting-Coefficients)\n",
    "    - [Model With Target Switched](#Model-With-Target-Switched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import re\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "menrelationship_df = pd.read_csv('../data/AskMen_Relationship.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensamble Model 2: With menrelationship_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models with Best Parameters from previous notebook\n",
    "cvec1 = CountVectorizer(max_df= 0.95, \n",
    "                       max_features= 2500, \n",
    "                       min_df= 2, \n",
    "                       ngram_range= (1,1))\n",
    "cvec2 = CountVectorizer(max_df= 0.95, \n",
    "                       max_features= 2000, \n",
    "                       min_df= 2, \n",
    "                       ngram_range= (1,1))\n",
    "tfidf1 = TfidfVectorizer(max_df= 0.95, \n",
    "                       max_features= 2000, \n",
    "                       min_df= 5, \n",
    "                       ngram_range= (1,1))\n",
    "\n",
    "tfidf2 = TfidfVectorizer(max_df= 0.95, \n",
    "                       max_features= 1500, \n",
    "                       min_df= 5, \n",
    "                       ngram_range= (1,2))\n",
    "mnb = MultinomialNB()\n",
    "logit = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building Pipeline\n",
    "pipe2 = Pipeline([\n",
    "#     ('cvec1', CountVectorizer(max_df= 0.95, \n",
    "#                        max_features= 2500, \n",
    "#                        min_df= 2, \n",
    "#                        ngram_range= (1,1))),  \n",
    "     \n",
    "#      ('cvec2', CountVectorizer(max_df= 0.95, \n",
    "#                        max_features= 2000, \n",
    "#                        min_df= 2, \n",
    "#                        ngram_range= (1,1))),\n",
    "     \n",
    "#      ('tfidf1', TfidfVectorizer(max_df= 0.95, \n",
    "#                        max_features= 2000, \n",
    "#                        min_df= 5, \n",
    "#                        ngram_range= (1,1))),\n",
    "     \n",
    "     ('tfidf2',  TfidfVectorizer(max_df= 0.95, #keep this one since it give us highest train test score \n",
    "                       max_features= 1500, \n",
    "                       min_df= 5, \n",
    "                       ngram_range= (1,2))),\n",
    "     \n",
    "    ('vc', VotingClassifier(estimators= [('mnb', mnb),\n",
    "                                   ('logit', logit)], \n",
    "                     voting = 'hard'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = menrelationship_df[\"Title_Content\"]\n",
    "y = menrelationship_df['Subreddit']\n",
    "\n",
    "#Train Test Split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evelyn/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf2', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.95, max_features=1500, min_df=5,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=Tru...0, warm_start=False))],\n",
       "         flatten_transform=None, n_jobs=None, voting='hard', weights=None))])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.9488636363636364\n",
      "test score 0.9359823399558499\n"
     ]
    }
   ],
   "source": [
    "print('train score', pipe2.score(X_train, y_train))\n",
    "print('test score', pipe2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Coefficients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-7.71977346, -7.72375633, -5.68410029, ..., -8.34486223,\n",
       "       -8.10852961, -7.26970552])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe2.named_steps['vc'].estimators_[0].coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting coefficients \n",
    "mnb2_coef = pipe2.named_steps['vc'].estimators_[0].coef_[0]\n",
    "\n",
    "logit2_coef = pipe2.named_steps['vc'].estimators_[1].coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get column names for man relationship columns\n",
    "tfidf = TfidfVectorizer(max_df= 0.95,\n",
    "                       max_features= 1500, \n",
    "                       min_df= 5, \n",
    "                       ngram_range= (1,2))\n",
    "tfidf.fit_transform(X_train)\n",
    "\n",
    "#Saving column name\n",
    "col_name2 = tfidf.get_feature_names()\n",
    "len(col_name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_coef</th>\n",
       "      <th>logit_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>able</th>\n",
       "      <td>-7.719773</td>\n",
       "      <td>-0.126985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>able to</th>\n",
       "      <td>-7.723756</td>\n",
       "      <td>-0.097881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>about</th>\n",
       "      <td>-5.684100</td>\n",
       "      <td>0.531166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>about her</th>\n",
       "      <td>-7.660617</td>\n",
       "      <td>0.125422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>about him</th>\n",
       "      <td>-8.116777</td>\n",
       "      <td>0.081896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            nb_coef  logit_coef\n",
       "able      -7.719773   -0.126985\n",
       "able to   -7.723756   -0.097881\n",
       "about     -5.684100    0.531166\n",
       "about her -7.660617    0.125422\n",
       "about him -8.116777    0.081896"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "menrelationship_word = pd.DataFrame(data= [mnb2_coef, logit2_coef], columns= col_name2, index= ['nb_coef', 'logit_coef'])\n",
    "menrelationship_word = menrelationship_word.T\n",
    "menrelationship_word.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
